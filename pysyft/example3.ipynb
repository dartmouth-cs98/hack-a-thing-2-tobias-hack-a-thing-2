{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fed. Learning with Model Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import syft as sy\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data owners!\n",
    "toby = sy.VirtualWorker(hook, id='toby')\n",
    "julie = sy.VirtualWorker(hook, id='julie')\n",
    "secure_machine = sy.VirtualWorker(hook, id='secure_worker')\n",
    "\n",
    "# Fake Dataset (pulled from tutorial)\n",
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
    "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
    "\n",
    "# same way to get data as I did in example1\n",
    "toby_data = data[0:2]\n",
    "toby_target = target[0:2]\n",
    "\n",
    "julie_data = data[2:]\n",
    "julie_target = target[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toby_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toby_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 1.]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "julie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "julie_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toby_data = toby_data.send(toby)\n",
    "toby_target = toby_target.send(toby)\n",
    "\n",
    "julie_data = julie_data.send(julie)\n",
    "julie_target = julie_target.send(julie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{14821136741: tensor([[0., 0.],\n",
       "         [0., 1.]], requires_grad=True),\n",
       " 65833685749: tensor([[0.],\n",
       "         [0.]], requires_grad=True)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toby_data.location._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:53583708348 -> toby:65833685749]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toby_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:69408708435 -> julie:42773609519]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "julie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:18226774777 -> julie:44233108398]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "julie_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=1, bias=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{14821136741: tensor([[0., 0.],\n",
       "         [0., 1.]], requires_grad=True),\n",
       " 65833685749: tensor([[0.],\n",
       "         [0.]], requires_grad=True)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# want to make sure things look the same\n",
    "toby_data.location._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toby Loss: tensor(0.0269)\n",
      "Julie Loss: tensor(0.0585)\n",
      "Toby Loss: tensor(0.0068)\n",
      "Julie Loss: tensor(0.0260)\n",
      "Toby Loss: tensor(0.0011)\n",
      "Julie Loss: tensor(0.0106)\n",
      "Toby Loss: tensor(3.5893e-05)\n",
      "Julie Loss: tensor(0.0044)\n",
      "Toby Loss: tensor(8.9421e-05)\n",
      "Julie Loss: tensor(0.0019)\n",
      "Toby Loss: tensor(0.0003)\n",
      "Julie Loss: tensor(0.0009)\n",
      "Toby Loss: tensor(0.0004)\n",
      "Julie Loss: tensor(0.0005)\n",
      "Toby Loss: tensor(0.0004)\n",
      "Julie Loss: tensor(0.0003)\n"
     ]
    }
   ],
   "source": [
    "# Train models in parallel, send updated models to worker, average models\n",
    "\n",
    "iters = 8\n",
    "worker_iters = 4\n",
    "\n",
    "for counter in range(iters):\n",
    "    \n",
    "    # send models\n",
    "    toby_model = model.copy().send(toby)\n",
    "    julie_model = model.copy().send(julie)\n",
    "\n",
    "    # build my optimizer with a learning rate of 0.15\n",
    "    toby_opt = optim.SGD(params=toby_model.parameters(), lr=0.15)\n",
    "    julie_opt = optim.SGD(params=julie_model.parameters(), lr=0.15)\n",
    "    \n",
    "    for worker_ctr in range(worker_iters):\n",
    "        \n",
    "        # Train Toby model\n",
    "        toby_opt.zero_grad()\n",
    "        toby_pred = toby_model(toby_data)\n",
    "        toby_loss = ((toby_pred - toby_target)**2).sum()\n",
    "        toby_loss.backward()\n",
    "        \n",
    "        toby_opt.step()\n",
    "        toby_loss = toby_loss.get().data\n",
    "        \n",
    "        # Train Julie's Model\n",
    "        \n",
    "        julie_opt.zero_grad()\n",
    "        julie_pred = julie_model(julie_data)\n",
    "        julie_loss = ((julie_pred - julie_target)**2).sum()\n",
    "        julie_loss.backward()\n",
    "        \n",
    "        julie_opt.step()\n",
    "        julie_loss = julie_loss.get().data\n",
    "    \n",
    "    # send it to the secure worker\n",
    "    toby_model.move(secure_machine)\n",
    "    julie_model.move(secure_machine)\n",
    "    \n",
    "    # set the weights and biases to be an average of our two workers; divide weight.data by n for number of workers\n",
    "    with torch.no_grad():\n",
    "        model.weight.set_(((julie_model.weight.data + toby_model.weight.data) / 2).get())\n",
    "        model.bias.set_(((julie_model.bias.data + toby_model.bias.data) / 2).get())\n",
    "        \n",
    "    print (\"Toby Loss: \" + str(toby_loss) + \"\\n\" + \"Julie Loss: \" + str(julie_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can see how well the model worked\n",
    "predictions = model(data)\n",
    "loss = ((predictions - target) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0798],\n",
      "        [0.0755],\n",
      "        [0.8967],\n",
      "        [0.8923]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "tensor(0.0343)\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(target)\n",
    "print(loss.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
